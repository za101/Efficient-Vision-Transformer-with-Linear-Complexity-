{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFFXOJOGIdBA"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "- load_pretrained_weights: load pretrained paramters to model in transfer learning\n",
        "- resize_pos_embed: resize position embedding\n",
        "- get_mean_and_std: calculate the mean and std value of dataset.\n",
        "'''\n",
        "import torch\n",
        "import math\n",
        "\n",
        "import logging\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "import torch.nn.functional as F\n",
        "\n",
        "_logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def resize_pos_embed(posemb, posemb_new):\n",
        "    '''\n",
        "    resize position embedding with class token\n",
        "    example: 224:(14x14+1)-> 384: (24x24+1)\n",
        "    return: new position embedding\n",
        "    '''\n",
        "    ntok_new = posemb_new.shape[1]\n",
        "\n",
        "    posemb_tok, posemb_grid = posemb[:, :1], posemb[0,1:]  # posemb_tok is for cls token, posemb_grid for the following tokens\n",
        "    ntok_new -= 1\n",
        "    gs_old = int(math.sqrt(len(posemb_grid)))  # 14\n",
        "    gs_new = int(math.sqrt(ntok_new))  # 24\n",
        "    _logger.info('Position embedding grid-size from %s to %s', gs_old, gs_new)\n",
        "    posemb_grid = posemb_grid.reshape(1, gs_old, gs_old, -1).permute(\n",
        "        0, 3, 1, 2)  # [1, 196, dim]->[1, 14, 14, dim]->[1, dim, 14, 14]\n",
        "    posemb_grid = F.interpolate(\n",
        "        posemb_grid, size=(gs_new, gs_new),\n",
        "        mode='bicubic')  # [1, dim, 14, 14] -> [1, dim, 24, 24]\n",
        "    posemb_grid = posemb_grid.permute(0, 2, 3, 1).reshape(\n",
        "        1, gs_new * gs_new, -1)  # [1, dim, 24, 24] -> [1, 24*24, dim]\n",
        "    posemb = torch.cat([posemb_tok, posemb_grid], dim=1)  # [1, 24*24+1, dim]\n",
        "    return posemb\n",
        "\n",
        "\n",
        "def resize_pos_embed_without_cls(posemb, posemb_new):\n",
        "    '''\n",
        "    resize position embedding without class token\n",
        "    example: 224:(14x14)-> 384: (24x24)\n",
        "    return new position embedding\n",
        "    '''\n",
        "    ntok_new = posemb_new.shape[1]\n",
        "    posemb_grid = posemb[0]\n",
        "    gs_old = int(math.sqrt(len(posemb_grid)))  # 14\n",
        "    gs_new = int(math.sqrt(ntok_new))  # 24\n",
        "    _logger.info('Position embedding grid-size from %s to %s', gs_old, gs_new)\n",
        "    posemb_grid = posemb_grid.reshape(1, gs_old, gs_old, -1).permute(\n",
        "        0, 3, 1, 2)  # [1, 196, dim]->[1, 14, 14, dim]->[1, dim, 14, 14]\n",
        "    posemb_grid = F.interpolate(\n",
        "        posemb_grid, size=(gs_new, gs_new),\n",
        "        mode='bicubic')  # [1, dim, 14, 14] -> [1, dim, 24, 24]\n",
        "    posemb_grid = posemb_grid.permute(0, 2, 3, 1).reshape(\n",
        "        1, gs_new * gs_new, -1)  # [1, dim, 24, 24] -> [1, 24*24, dim]\n",
        "    return posemb_grid\n",
        "\n",
        "\n",
        "def resize_pos_embed_4d(posemb, posemb_new):\n",
        "    '''return new position embedding'''\n",
        "    # Rescale the grid of position embeddings when loading from state_dict. Adapted from\n",
        "    # https://github.com/google-research/vision_transformer/blob/00883dd691c63a6830751563748663526e811cee/vit_jax/checkpoint.py#L224\n",
        "    gs_old = posemb.shape[1]  # 14\n",
        "    gs_new = posemb_new.shape[1]  # 24\n",
        "    _logger.info('Position embedding grid-size from %s to %s', gs_old, gs_new)\n",
        "    posemb_grid = posemb\n",
        "    posemb_grid = posemb_grid.permute(0, 3, 1,\n",
        "                                      2)  # [1, 14, 14, dim]->[1, dim, 14, 14]\n",
        "    posemb_grid = F.interpolate(posemb_grid, size=(gs_new, gs_new), mode='bicubic')  # [1, dim, 14, 14] -> [1, dim, 24, 24]\n",
        "    posemb_grid = posemb_grid.permute(0, 2, 3, 1)  # [1, dim, 24, 24]->[1, 24, 24, dim]\n",
        "    return posemb_grid\n",
        "\n",
        "def load_state_dict(checkpoint_path, model, use_ema=False, num_classes=1000):\n",
        "    # load state_dict\n",
        "    if checkpoint_path and os.path.isfile(checkpoint_path):\n",
        "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "        state_dict_key = 'state_dict'\n",
        "        if isinstance(checkpoint, dict):\n",
        "            if use_ema and 'state_dict_ema' in checkpoint:\n",
        "                state_dict_key = 'state_dict_ema'\n",
        "        if state_dict_key and state_dict_key in checkpoint:\n",
        "            new_state_dict = OrderedDict()\n",
        "            for k, v in checkpoint[state_dict_key].items():\n",
        "                # strip `module.` prefix\n",
        "                name = k[7:] if k.startswith('module') else k\n",
        "                new_state_dict[name] = v\n",
        "            state_dict = new_state_dict\n",
        "        else:\n",
        "            state_dict = checkpoint\n",
        "        _logger.info(\"Loaded {} from checkpoint '{}'\".format(\n",
        "            state_dict_key, checkpoint_path))\n",
        "        if num_classes != 1000:\n",
        "            # completely discard fully connected for all other differences between pretrained and created model\n",
        "            del state_dict['head' + '.weight']\n",
        "            del state_dict['head' + '.bias']\n",
        "            old_aux_head_weight = state_dict.pop('aux_head.weight', None)\n",
        "            old_aux_head_bias = state_dict.pop('aux_head.bias', None)\n",
        "\n",
        "        old_posemb = state_dict['pos_embed']\n",
        "        if model.pos_embed.shape != old_posemb.shape:  # need resize the position embedding by interpolate\n",
        "            if len(old_posemb.shape) == 3:\n",
        "                if int(math.sqrt(\n",
        "                        old_posemb.shape[1]))**2 == old_posemb.shape[1]:\n",
        "                    new_posemb = resize_pos_embed_without_cls(\n",
        "                        old_posemb, model.pos_embed)\n",
        "                else:\n",
        "                    new_posemb = resize_pos_embed(old_posemb, model.pos_embed)\n",
        "            elif len(old_posemb.shape) == 4:\n",
        "                new_posemb = resize_pos_embed_4d(old_posemb, model.pos_embed)\n",
        "            state_dict['pos_embed'] = new_posemb\n",
        "\n",
        "        return state_dict\n",
        "    else:\n",
        "        _logger.error(\"No checkpoint found at '{}'\".format(checkpoint_path))\n",
        "        raise FileNotFoundError()\n",
        "\n",
        "\n",
        "def load_pretrained_weights(model,\n",
        "                            checkpoint_path,\n",
        "                            use_ema=False,\n",
        "                            strict=True,\n",
        "                            num_classes=1000):\n",
        "    '''load pretrained weight for VOLO models'''\n",
        "    state_dict = load_state_dict(checkpoint_path, model, use_ema, num_classes)\n",
        "    model.load_state_dict(state_dict, strict=strict)\n",
        "\n",
        "\n",
        "def get_mean_and_std(dataset):\n",
        "    '''Compute the mean and std value of dataset.'''\n",
        "    dataloader = torch.utils.data.DataLoader(dataset,\n",
        "                                             batch_size=1,\n",
        "                                             shuffle=True,\n",
        "                                             num_workers=2)\n",
        "    mean = torch.zeros(3)\n",
        "    std = torch.zeros(3)\n",
        "    print('==> Computing mean and std..')\n",
        "    for inputs, targets in dataloader:\n",
        "        for i in range(3):\n",
        "            mean[i] += inputs[:, i, :, :].mean()\n",
        "            std[i] += inputs[:, i, :, :].std()\n",
        "    mean.div_(len(dataset))\n",
        "    std.div_(len(dataset))\n",
        "    return mean, std"
      ]
    }
  ]
}